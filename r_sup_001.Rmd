---
title: "vs_sup"
author: "drsimonturega"
date: "2025-12-16"
output:
  pdf_document: default
  html_document: default
---

```{r include=FALSE}
# Installing libraries required for our lecture
#installed rmarkdown ggplot2
library(tidyverse)
#install.packages("reshape2")
library(reshape2)
library(ggplot2)
# You may have to instal tinytex
#tinytex::install_tinytex()
#install.packages("Metrics")
#install.packages("rtools")
#install.packages("randomForest")
library(randomForest)
library(Metrics)
library(caret)
#install.packages("neuralnet")
library(neuralnet)
```

# Virtual screening for high affinity guests for synthetic supramolecular receptors

### Orginal literature

<https://doi.org/10.1039/C5SC00534E>

### Functions used in this analysis
I don't have a R data science package(library) yet... 
```{r my_functions, echo=FALSE}

get_column_value <- function(d_frame, d_col) {
  # Use get() to retrieve the column by its string name
  # expand to use d_cal being a list
  get(d_col, d_frame)
}


hist_ylims <- function(dens){
  # Get y axis limits for a column from a data frame
  #data = get_column_value(d_frame, d_col)
  ylim = c(min(dens$y), c(max(dens$y)))
  return(ylim)
  }

int_made_even<- function(num){
  # make an int even
  if((num %% 2) != 0) 
    return(num+1)
  else
    return(num)
 }
  

hist_kde <- function(d_frame, d_col){
  # Colored Histogram with KDE line for clarity
  data  = get_column_value(d_frame, d_col )
  dens <- density(data)
  hist(data, main=d_col, xlab = d_col, ylim = (hist_ylims(dens)), col="blue", freq = FALSE)
  lines(dens, lwd = 2,  col = "black")
}

q_q_plot <- function(d_frame, d_col){
  # Generate a quartile quartile plot
  data  = get_column_value(d_frame, d_col )
  qqnorm(data, main = d_col,  pch = 1)
  qqline(data, col = "blue", lwd = 2)
}

multi_plot <- function(d_frame,plot_t){
 # multi plot 
  n_col = ncol(d_frame)
  n_plot = int_made_even(n_col)
  col_names = colnames(d_frame)
  # make plots
  par(mfrow=c(2,(n_plot/2) ))
  for (col in col_names)
    plot_t(d_frame, col)
}

get_upper_tri <- function(mat){
  # split correlation matrix in have retain upper half
  mat[lower.tri(mat)]<- NA
  return(mat)
  }

get_lower_tri <- function(mat){
  # split correlation matrix in have retain upper half
  mat[upper.tri(mat)]<- NA
  return(mat)
}

reorder_cormat <- function(mat){
  # Use correlation between variables as distance
  dd <- as.dist((1-mat)/2)
  hc <- hclust(dd)
  mat <-mat[hc$order, hc$order]
  return(mat)
}

mat_rear <- function(mat){
  mat = round(cor(mat),2)
  mat = reorder_cormat(mat) # order Vars from low to high
  mat = get_upper_tri(mat)
  return(mat)
}

correl_mat_plot <- function(mat, title){
  mat = round(cor(mat),2)
  mat = reorder_cormat(mat) # order Vars from low to high
  mat = get_upper_tri(mat)
  mat = melt(mat, na.rm = TRUE)
  ggplot(data = mat, aes(x = Var2, y = Var1, fill = value))+
    geom_tile(color = "white")+
    scale_fill_gradient2(low = "darkblue", high = "lightblue", mid = "white", 
      midpoint = 0, limit = c(-1,1), space = "Lab", 
      name="Pearson\nCorrelation") +
     theme_minimal()+
    # adds Pearson correlation values
    geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
    theme(axis.text.x = element_text(angle = 45, vjust = 1,
      size = 12, hjust = 1)) +
    theme(
      axis.title.x = element_blank(),
      axis.title.y = element_blank()) +
    ggtitle(title) +
    theme(plot.title = element_text(hjust = 0.5)) +
    coord_fixed()
}

correl_mat_plot_2 <- function(mat, title){
  mat = round(cor(mat),2)
  mat = reorder_cormat(mat) # order Vars from low to high
  mat = get_upper_tri(mat)
  mat = melt(mat, na.rm = TRUE)
  ggplot(data = mat, aes(x = Var2, y = Var1, fill = value))+
    geom_tile(color = "white")+
    scale_fill_gradient2(low = "darkblue", high = "white", mid = "lightblue", 
      midpoint = 0, limit = c(-1,1), space = "Lab", 
      name="Pearson\nCorrelation") +
     theme_minimal()+
    # adds Pearson correlation values
    geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
    theme(axis.text.x = element_text(angle = 45, vjust = 1,
      size = 12, hjust = 1)) +
    theme(
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
       panel.grid.major = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      axis.ticks = element_blank(),
      legend.justification = c(1, 0),
      legend.position = c(0.6, 0.7),
      legend.direction = "horizontal")+
      guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))+
    
    ggtitle(title) +
    theme(plot.title = element_text(hjust = 0.5)) +
    coord_fixed()
}


correl_mat_plot_3 <- function(mat, title){
  # no numerical values for correlations
  mat = round(cor(mat),2)
  mat = reorder_cormat(mat) # order Vars from low to high
  mat = get_upper_tri(mat)
  mat = melt(mat, na.rm = TRUE)
  ggplot(data = mat, aes(x = Var2, y = Var1, fill = value))+
    geom_tile(color = "white")+
    scale_fill_gradient2(low = "darkblue", high = "white", mid = "lightblue", 
      midpoint = 0, limit = c(-1,1), space = "Lab", 
      name="Pearson\nCorrelation") +
     theme_minimal()+
    # adds Pearson correlation values
    #geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
    theme(axis.text.x = element_text(angle = 45, vjust = 1,
      size = 12, hjust = 1)) +
    theme(
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
       panel.grid.major = element_blank(),
      panel.border = element_blank(),
      panel.background = element_blank(),
      axis.ticks = element_blank(),
      legend.justification = c(1, 0),
      legend.position = c(0.6, 0.7),
      legend.direction = "horizontal")+
      guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                title.position = "top", title.hjust = 0.5))+
    
    ggtitle(title) +
    theme(plot.title = element_text(hjust = 0.5)) +
    coord_fixed()
}
  
```

## Replication of our analysis in the manuscript using R
We take a set df cleaned and prepared in the python verson of this lecture.

### We load cleaned data molecular descriptors from the supporting information
Students, visualise the molecular descriptors using R studio

```{r load datata science style df}
df = read.csv("tab_gold_wt.csv", header = TRUE)
```

### We load cleaned chemplp_score data from the supporting information

```{r load df for first manuscript plot}
df_chemplp_score = read.csv("chemplp_score.csv", header = TRUE)
dim(df_chemplp_score)
```

### Comparision of logKexp and ChemPLP_Score for training set from the manuscript
```{r linear regession}
corr_man = lm(ChemPLP_Score~logKexpt, data = df_chemplp_score)

summary(corr_man)$r.squared
```

```{r plotting logKexp vs ChemPLP_Score}

lm_rsq <- function(mod){
    m <- mod;
    rsq <- substitute(italic(r)^2~"="~r2, 
         list(r2 = format(summary(m)$r.squared, digits = 3)))
    as.character(as.expression(rsq));
}



ggplot(data = df_chemplp_score, aes(x=logKexpt, y=ChemPLP_Score)) +
  geom_point(size=3, shape=23) +
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = 'black', 
                                    fill = NA, 
                                    size = 2),
    panel.background = element_blank()) +
  geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
  geom_text(x = 1, y = 60, label = lm_rsq(corr_man), parse = TRUE)
  
#print(lm_rsq(corr_man))
```

### Multivariate linear regression on the training set from the manuscript using eq. 2
The eq.2 includes molecular descriptors calculated in Gold. Then we slice our data set as in the manuscript and check dimensions.
```{r Slicing our df to replicate manuscript}
df_train <- df[1:54,]
df_test <- df[55:69,]
print("Dimensions of training set")
print(dim(df_train))
print("Dimensions of test set")
print(dim(df_test))
```
We run our regression model calculating a correct analysis of the model by plotting logKexp vs. logKcalc and calculating the rmse. This allows us to test our hypothesis, that we can use the molecular descriptors calculated in Gold to build our own predictive model for cage-guest binding and evaluate the model.
```{r run regression analysis}
# no ligand_flexibility
eq2_lm = lm(logKexp~Ligand_clash + Ligand_torsion + Part_buried + Non.polar,data = df_train)
summary(eq2_lm)
```

```{r predict logK for training set}
logKcalc = predict(eq2_lm, select(df_train,c(1:5)))
```

```{r calculate rmse for this model}
df_train["logKcalc"] = logKcalc
rmse_value <- rmse(df_train$logKcalc, df_train$logKexp)
```

```{r plot logKexp vs logKcalc}
ggplot(data = df_train, aes(x=logKexp, y=logKcalc)) +
  geom_point(size=3, shape=23) +
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = 'black', 
                                    fill = NA, 
                                    size = 2),
    panel.background = element_blank()) +
  geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
  geom_text(x = 1, y = -2, label = rmse_value, parse = TRUE)
paste("rmse = ", rmse_value)
```

### Multivariate linear regression on the training set from the manuscript using eq. 3
The eq.3 includes a molecular descriptor for ligand flexibility this was calculated outside of gold. Then we slice our data set as in the manuscript and check dimensions.
```{r Slicing our df to replicate manuscript}
df_train <- df[1:54,]
df_test <- df[55:69,]
print("Dimensions of training set")
print(dim(df_train))
print("Dimensions of test set")
print(dim(df_test))
```
Then run our regression model calculating a correct analysis of the model by plotting logKexp vs. logKcalc and calculating the rmse. This allows us to test our hypothesis, that we can use the molecular descriptors calculated in Gold to build our own predictive model for cage-guest binding and evaluate the model.
```{r run regression analysis}
# with ligand_flexibility
eq3_lm = lm(logKexp~Ligand_clash + Ligand_torsion + Part_buried + Non.polar
             + Ligand_flexibility, data = df_train)
summary(eq3_lm)
```

```{r predict logK for training set}


logKcalc = predict(eq3_lm, select(df_train,c(1:6)))
```


```{r calculate rmse for this model}

df_train["logKcalc"] = logKcalc
rmse_value <- rmse(df_train$logKcalc, df_train$logKexp)


```

```{r plot logKexp vs logKcalc}

ggplot(data = df_train, aes(x=logKexp, y=logKcalc)) +
  geom_point(size=3, shape=23) +
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = 'black', 
                                    fill = NA, 
                                    size = 2),
    panel.background = element_blank()) +
  geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) #+
  #geom_text(x = 1, y = -2, label = rmse_value, parse = TRUE)
  
paste("rmse = ", rmse_value)
```
### Analysis of new guests from the manuscripts
To rapidly test our model we computationaly screened the labs inventory using the eq. 3 model to quickly find molecules to test the predictive model with. 
```{r predict logK for test set}
logKcalc_test = predict(eq3_lm, select(df_test,c(1:6)))
```

```{r calculate rmse for this model}
df_test["logKcalc"] = logKcalc_test
rmse_value <- rmse(df_test$logKcalc, df_test$logKexp)
```

```{r plot logKexp vs logKcalc}
ggplot(data = df_test, aes(x=logKexp, y=logKcalc)) +
  geom_point(size=3, shape=23) +
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = 'black', 
                                    fill = NA, 
                                    size = 2),
    panel.background = element_blank()) +
  geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) #+
  #geom_text(x = 1, y = -2, label = rmse_value, parse = TRUE)
paste("rmse = ", rmse_value)

```

## END OF LECTURE ONE



## Modern data science approach using eq3

## Run some exploratory data analysis

### Data summary

```{r }
summary(df)
```
 we still have guest number the data frame we will remove it
 

 
```{r remove column with guest number}
 df <- df[-c(1)]
 summary(df)
```


### Histogram with KDE line for clarity
The histogram is in blue bars. The Kernel Density Estimation line is and estimation of the histogram represented as a continuous line and is shown as a black line.
```{r Histogram with KDE line}
hist_kde(df, "Part_buried")
```
Its helpful to plot all dataframe columns
```{r multi histogram with KDE line}
multi_plot(df, hist_kde)
```

### Quantile quantile plots
Our quantile quantile plots show us weather our data fits to a theoretical distribution 
```{r multi-plot quantile quantile }
multi_plot(df, q_q_plot)

```

This is experimental data from 69 individual data points our team generated, so we don't really expect it to fit a normal distribution. We would expect the replicates of **logKexp** to fit a normal distribution and the error quoted in the manuscript at 95% confidence. The data will correlate to a scientific hypothesis!

### Correlation matrix heatmap
Over correlated molecular descriptor (GoldPLP functions)  columns can cause problems with our regression models. Too many correlated molecular descriptor cause a misrepresentation of those molecular descriptors in our regression model.
```{r preparing the data}
cor_mat <- round(cor(df),2)
head(cor_mat)
```
Reshape our dataframe
```{r reshape data}
melted_cor_mat <- melt(cor_mat)
head(melted_cor_mat)
```
```{r corr heatmap}
ggplot(data = melted_cor_mat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() +
  ggtitle("Correlation plot for functions from GoldPLP") +
  theme(plot.title = element_text(hjust = 0.5))
```

```{r neater correlatio matrix_2}
correl_mat_plot_2(df, "Correlation plot for functions from GoldPLP")
```

```{r neater correlatio matrix_3}
correl_mat_plot_3(df, "Correlation plot for functions from GoldPLP")
```

You can make your correlation plot neater but they are not really pretty.

### Normalise our df 

```{r}
head(df)
```
```{r}
process <- preProcess(as.data.frame(df[1:5]), method=c("range"))
df[1:5] <- predict(process, as.data.frame(df[1:5]))
```

```{r}
head(df)
```
### A random forest decision tree method
#### Splitting our data in to training and test sets

``` {r spliting our data}
set.seed(89)
sample <- sample.int(n = nrow(df), size = floor(.80*nrow(df)), replace = F)
train <- df[sample, ]
test  <- df[-sample, ]
print("Dimensions of training set")
print(dim(train))
print("Dimensions of test set")
print(dim(test))
```
Fit our regression model and produce a description of the model, be-aware this is not the analysis of our model.
```{r}
logK.rf <- randomForest(logKexp ~ ., data = train, mtry = 3, importance = TRUE)
print(logK.rf)
```
Then run our regression model calculating a correct analysis of the model by plotting logKexp vs. logKcalc and calculating the rmse. This allows us to test our hypothesis, that we can use the molecular descriptors calculated in Gold to build our own predictive model for cage-guest binding and evaluate the model.
```{r prediction of logK for training set}
train["logKcalc"] <- predict(logK.rf, train)
```

```{r calaculate rmse}
rmse_value <- rmse(train$logKcalc, train$logKexp)
```

```{r plot logKexp vs logKcalc}
ggplot(data = train, aes(x=logKexp, y=logKcalc)) +
  geom_point(size=3, shape=23) +
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = 'black', 
                                    fill = NA, 
                                    size = 2),
    panel.background = element_blank()) +
  geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) +
  geom_text(x = 1, y = -2, label = rmse_value, parse = TRUE)
  
paste("rmse = ", rmse_value)
```

```{r prediction of logK for training set}
test["logKcalc"] <- predict(logK.rf, test)
```

```{r calaculate rmse}
rmse_value <- rmse(test$logKcalc, test$logKexp)
```

```{r plot logKexp vs logKcalc}
ggplot(data = test, aes(x=logKexp, y=logKcalc)) +
  geom_point(size=3, shape=23) +
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = 'black', 
                                    fill = NA, 
                                    size = 2),
    panel.background = element_blank()) +
  geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) #+
  #geom_text(x = 1, y = -2, label = rmse_value, parse = TRUE)
  paste("rmse = ", rmse_value)
```
### A Multilayer Perceptron neural networks method
#### Splitting our data in to training and test sets
```{r}
set.seed(89)
sample <- sample.int(n = nrow(df), size = floor(.80*nrow(df)), replace = F)
train <- df[sample, ]
test  <- df[-sample, ]
print("Dimensions of training set")
print(dim(train))
print("Dimensions of test set")
print(dim(test))
```
Then run our regression model calculating a correct analysis of the model by plotting logKexp vs. logKcalc and calculating the rmse. This allows us to test our hypothesis, that we can use the molecular descriptors calculated in Gold to build our own predictive model for cage-guest binding and evaluate the model.
```{r formulate and train the MLP}
# formulate eq 3 for our model
eq_3_form <- logKexp~Ligand_clash + Ligand_torsion + Part_buried + Non.polar + Ligand_flexibility
# Train the MLP model
model <- neuralnet(eq_3_form, data = train, hidden = c(5, 3), linear.output = TRUE, stepmax=1e7)
```
Produce a description of the model, be-aware this is not the analysis of our model.
```{r}
plot(model)
```

```{r prediction of logK for training set}
train["logKcalc"] <- predict(model, train)
#head(train)
```

```{r calaculate rmse}
rmse_value <- rmse(train$logKcalc, train$logKexp)
```

```{r plot logKexp vs logKcalc}
ggplot(data = train, aes(x=logKexp, y=logKcalc)) +
  geom_point(size=3, shape=23) +
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = 'black', 
                                    fill = NA, 
                                    size = 2),
    panel.background = element_blank()) +
  geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) #+
  #geom_text(x = 1, y = -2, label = rmse_value, parse = TRUE)
  
paste("rmse = ", rmse_value)
```

```{r prediction of logK for test set}
test["logKcalc"] <- predict(model, test)
#head(test)
```

```{r calaculate rmse}
rmse_value <- rmse(test$logKcalc, test$logKexp)
```

```{r plot logKexp vs logKcalc}
ggplot(data = test, aes(x=logKexp, y=logKcalc)) +
  geom_point(size=3, shape=23) +
  theme(axis.line = element_line(colour = "black"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = 'black', 
                                    fill = NA, 
                                    size = 2),
    panel.background = element_blank()) +
  geom_smooth(method = "lm", se=FALSE, color="black", formula = y ~ x) #+
  #geom_text(x = 1, y = -2, label = rmse_value, parse = TRUE)
paste("rmse = ", rmse_value)
```
